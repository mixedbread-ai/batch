{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T01:09:30.956638Z",
     "start_time": "2024-08-24T01:09:30.182485Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single item results:\n",
      "HELLO, WORLD! (Processed: 1)\n",
      "PYTHON IS AWESOME (Processed: 2)\n",
      "ASYNC IS AWESOME (Processed: 3)\n",
      "\n",
      "Batch processing results (first 5):\n",
      "TEXT 0 (Processed: 4)\n",
      "TEXT 1 (Processed: 102)\n",
      "TEXT 2 (Processed: 5)\n",
      "TEXT 3 (Processed: 103)\n",
      "TEXT 4 (Processed: 101)\n",
      "\n",
      "Batch processing statistics:\n",
      "BatchProcessorStats(queue_size=0, total_processed=103, total_batches=7, avg_batch_size=14.714285714285714, avg_processing_time=0.1030510493687221)\n"
     ]
    }
   ],
   "source": [
    "import batch\n",
    "import time\n",
    "\n",
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.processed_count = 0\n",
    "\n",
    "    @batch.dynamically(batch_size=32, timeout_ms=10.0)\n",
    "    def process_text(self, texts: list[str]) -> list[str]:\n",
    "        # Simulate some processing time\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        # Convert texts to uppercase and add a counter\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            self.processed_count += 1\n",
    "            results.append(f\"{text.upper()} (Processed: {self.processed_count})\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "\n",
    "# Create an instance of TextProcessor\n",
    "processor = TextProcessor()\n",
    "\n",
    "# Process single items\n",
    "result1 = processor.process_text(\"Hello, world!\")\n",
    "result2 = processor.process_text(\"Python is awesome\")\n",
    "\n",
    "# Use async/await to process single items\n",
    "result3 = await processor.process_text.acall(\"Async is awesome\")\n",
    "\n",
    "print(\"Single item results:\")\n",
    "print(result1)\n",
    "print(result2)\n",
    "print(result3)\n",
    "\n",
    "# Process a batch of items\n",
    "batch_texts = [f\"Text {i}\" for i in range(100)]\n",
    "batch_results = processor.process_text(batch_texts)\n",
    "\n",
    "print(\"\\nBatch processing results (first 5):\")\n",
    "for result in batch_results[:5]:\n",
    "    print(result)\n",
    "\n",
    "# Check the statistics\n",
    "print(\"\\nBatch processing statistics:\")\n",
    "print(processor.process_text.stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3c042",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T01:10:24.699119Z",
     "start_time": "2024-08-24T01:10:22.199820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single sentence embedding shapes:\n",
      "Embedding 1 shape: (384,)\n",
      "Embedding 2 shape: (384,)\n",
      "\n",
      "Batch embedding shapes:\n",
      "Embedding 1 shape: (384,)\n",
      "Embedding 2 shape: (384,)\n",
      "Embedding 3 shape: (384,)\n",
      "Embedding 4 shape: (384,)\n",
      "Embedding 5 shape: (384,)\n",
      "\n",
      "Time taken to embed 1000 sentences: 0.4457 seconds\n",
      "\n",
      "Batch processing statistics:\n",
      "BatchProcessorStats(queue_size=0, total_processed=1003, total_batches=35, avg_batch_size=28.65714285714286, avg_processing_time=0.01271756717136928)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class SentenceEmbedder:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    @batch.dynamically(batch_size=32, timeout_ms=50.0)\n",
    "    def embed_sentences(self, sentences: list[str]) -> list[np.ndarray]:\n",
    "        # Convert sentences to embeddings\n",
    "        embeddings = self.model.encode(sentences)\n",
    "        return [embedding for embedding in embeddings]\n",
    "\n",
    "# Create an instance of SentenceEmbedder\n",
    "embedder = SentenceEmbedder()\n",
    "\n",
    "# Embed single sentences\n",
    "single_sentence1 = \"This is a test sentence.\"\n",
    "single_sentence2 = \"Another example sentence.\"\n",
    "embedding1 = embedder.embed_sentences(single_sentence1)\n",
    "embedding2 = embedder.embed_sentences(single_sentence2)\n",
    "\n",
    "# Use async/await to embed single sentences\n",
    "embedding3 = await embedder.embed_sentences.acall(\"Async is awesome\")\n",
    "\n",
    "print(\"Single sentence embedding shapes:\")\n",
    "print(f\"Embedding 1 shape: {embedding1.shape}\")\n",
    "print(f\"Embedding 2 shape: {embedding2.shape}\")\n",
    "\n",
    "# Embed a batch of 1000 sentences\n",
    "batch_sentences = [f\"This is test sentence number {i}.\" for i in range(1000)]\n",
    "\n",
    "start_time = time.time()\n",
    "batch_embeddings = embedder.embed_sentences(batch_sentences)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\nBatch embedding shapes:\")\n",
    "for i, embedding in enumerate(batch_embeddings[:5]):  # Print only first 5 for brevity\n",
    "    print(f\"Embedding {i+1} shape: {embedding.shape}\")\n",
    "\n",
    "print(f\"\\nTime taken to embed 1000 sentences: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Check the statistics\n",
    "print(\"\\nBatch processing statistics:\")\n",
    "print(embedder.embed_sentences.stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
