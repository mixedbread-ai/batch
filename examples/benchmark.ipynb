{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T18:23:50.926503Z",
     "start_time": "2024-08-21T18:17:40.919545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285d52e702e74a5a88d2dcda339b86ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455e51c5c2104058986fff9dd2871791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2463d847c57b41749d16def64345149c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  12%|#1        | 52.4M/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmarks...\n",
      "Forward called with args: () and kwargs: {'input_ids': tensor([[  101, 13971,  3899,  1996,  2829,  2058, 13971, 13971,  4248, 13971,\n",
      "          3899,   102],\n",
      "        [  101,  2058,  2829,  3899, 13971,  2829,  4419, 13971,  4419,  2058,\n",
      "          4248,   102],\n",
      "        [  101,  4419,  4419,  2058,  1996, 13971,  2829,  2829,  2058, 13971,\n",
      "         13971,   102],\n",
      "        [  101, 14523,  2058,  2058,  1996, 13971, 13971, 13971,  2058,  4419,\n",
      "          2058,   102],\n",
      "        [  101,  1996,  4248, 13971,  2829, 14523,  2829,  4419,  1996, 14523,\n",
      "          1996,   102],\n",
      "        [  101, 14523,  4248,  2058,  4248, 13971,  4419,  1996,  1996,  2829,\n",
      "         13971,   102],\n",
      "        [  101,  4248, 14523,  2058,  1996, 14523,  3899,  4248,  3899,  2829,\n",
      "          4248,   102],\n",
      "        [  101,  4248,  1996,  4248, 13971, 14523,  2058,  4248, 13971,  2058,\n",
      "          2058,   102],\n",
      "        [  101,  2829,  1996,  2829,  2058,  2058,  2058, 13971,  1996,  4248,\n",
      "          2829,   102],\n",
      "        [  101,  3899,  1996, 14523,  4248,  3899,  1996,  1996,  3899,  4419,\n",
      "         14523,   102],\n",
      "        [  101,  2058,  2829,  3899, 14523, 13971, 13971,  2058, 14523,  2829,\n",
      "          1996,   102],\n",
      "        [  101,  4248,  3899,  4419,  4248, 14523,  2058,  2058,  3899, 13971,\n",
      "          4248,   102],\n",
      "        [  101,  1996, 14523,  1996,  2058, 13971,  1996,  2829,  2058,  1996,\n",
      "          4248,   102],\n",
      "        [  101, 14523,  1996, 14523,  4419,  2058,  4419, 13971,  2829, 13971,\n",
      "          4248,   102],\n",
      "        [  101,  4419,  4419,  2058,  1996,  4419, 13971,  2058,  2058,  2829,\n",
      "          1996,   102],\n",
      "        [  101,  2829,  2058,  4248, 14523, 13971,  3899,  3899,  4419,  1996,\n",
      "          4419,   102],\n",
      "        [  101,  3899,  3899,  2058, 13971,  4248, 14523, 13971, 13971, 14523,\n",
      "          2829,   102],\n",
      "        [  101,  3899, 14523,  4248,  1996,  2058,  4419,  3899,  3899,  3899,\n",
      "          2829,   102],\n",
      "        [  101,  2829,  1996,  4419,  2829, 13971, 13971,  3899,  4248,  1996,\n",
      "          4248,   102],\n",
      "        [  101,  1996, 14523,  1996,  3899, 13971,  3899, 13971,  2829,  4419,\n",
      "          2829,   102],\n",
      "        [  101,  2829,  1996,  1996, 13971,  1996,  2829, 13971,  4248,  2829,\n",
      "          2829,   102],\n",
      "        [  101,  4419, 14523,  4248, 13971, 14523,  4419,  2058,  1996,  2829,\n",
      "         14523,   102],\n",
      "        [  101,  2058,  3899,  2058,  1996,  1996,  2058,  1996,  4419,  2058,\n",
      "         13971,   102],\n",
      "        [  101,  3899, 13971,  4419, 13971,  3899,  3899,  3899, 13971,  3899,\n",
      "         13971,   102],\n",
      "        [  101, 13971,  4419,  2829,  3899,  2058,  4248,  2058,  2829,  2058,\n",
      "         14523,   102],\n",
      "        [  101,  4248, 14523,  4419, 13971,  3899,  4248,  3899,  2829,  1996,\n",
      "          2058,   102],\n",
      "        [  101,  4419, 14523, 14523,  2058, 13971,  2058, 13971,  4419,  2829,\n",
      "         13971,   102],\n",
      "        [  101,  4248, 14523,  2829,  4419, 14523,  4419,  2058, 14523, 14523,\n",
      "          2058,   102],\n",
      "        [  101,  4419,  4248,  4419,  4248, 14523,  1996, 14523,  2829,  2829,\n",
      "          4248,   102],\n",
      "        [  101,  3899,  4248,  2058, 14523,  2058,  4419,  4419, 14523,  3899,\n",
      "          2058,   102],\n",
      "        [  101,  2829,  4419,  4419,  2829, 14523,  4419,  4419, 14523, 13971,\n",
      "          1996,   102],\n",
      "        [  101,  3899, 14523,  4419, 13971,  4248,  2058, 13971,  4419, 14523,\n",
      "          1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Forward called with args: ({'input_ids': tensor([[  101, 13971,  3899,  1996,  2829,  2058, 13971, 13971,  4248, 13971,\n",
      "          3899,   102],\n",
      "        [  101,  4419,  4419,  2058,  1996, 13971,  2829,  2829,  2058, 13971,\n",
      "         13971,   102],\n",
      "        [  101,  4248, 14523,  2058,  1996, 14523,  3899,  4248,  3899,  2829,\n",
      "          4248,   102],\n",
      "        [  101,  4419,  4419,  2058,  1996,  4419, 13971,  2058,  2058,  2829,\n",
      "          1996,   102],\n",
      "        [  101,  2829,  4419,  4419,  2829, 14523,  4419,  4419, 14523, 13971,\n",
      "          1996,   102],\n",
      "        [  101,  3899,  4248,  2058, 14523,  2058,  4419,  4419, 14523,  3899,\n",
      "          2058,   102],\n",
      "        [  101,  3899, 14523,  4419, 13971,  4248,  2058, 13971,  4419, 14523,\n",
      "          1996,   102],\n",
      "        [  101,  4419,  4248,  4419,  4248, 14523,  1996, 14523,  2829,  2829,\n",
      "          4248,   102],\n",
      "        [  101,  4248, 14523,  2829,  4419, 14523,  4419,  2058, 14523, 14523,\n",
      "          2058,   102],\n",
      "        [  101,  4419, 14523, 14523,  2058, 13971,  2058, 13971,  4419,  2829,\n",
      "         13971,   102],\n",
      "        [  101,  4248, 14523,  4419, 13971,  3899,  4248,  3899,  2829,  1996,\n",
      "          2058,   102],\n",
      "        [  101, 13971,  4419,  2829,  3899,  2058,  4248,  2058,  2829,  2058,\n",
      "         14523,   102],\n",
      "        [  101,  3899, 13971,  4419, 13971,  3899,  3899,  3899, 13971,  3899,\n",
      "         13971,   102],\n",
      "        [  101,  2058,  3899,  2058,  1996,  1996,  2058,  1996,  4419,  2058,\n",
      "         13971,   102],\n",
      "        [  101,  4419, 14523,  4248, 13971, 14523,  4419,  2058,  1996,  2829,\n",
      "         14523,   102],\n",
      "        [  101,  2829,  1996,  1996, 13971,  1996,  2829, 13971,  4248,  2829,\n",
      "          2829,   102],\n",
      "        [  101,  1996, 14523,  1996,  3899, 13971,  3899, 13971,  2829,  4419,\n",
      "          2829,   102],\n",
      "        [  101,  2829,  1996,  4419,  2829, 13971, 13971,  3899,  4248,  1996,\n",
      "          4248,   102],\n",
      "        [  101,  3899, 14523,  4248,  1996,  2058,  4419,  3899,  3899,  3899,\n",
      "          2829,   102],\n",
      "        [  101,  3899,  3899,  2058, 13971,  4248, 14523, 13971, 13971, 14523,\n",
      "          2829,   102],\n",
      "        [  101, 14523,  1996, 14523,  4419,  2058,  4419, 13971,  2829, 13971,\n",
      "          4248,   102],\n",
      "        [  101,  2829,  2058,  4248, 14523, 13971,  3899,  3899,  4419,  1996,\n",
      "          4419,   102],\n",
      "        [  101,  1996, 14523,  1996,  2058, 13971,  1996,  2829,  2058,  1996,\n",
      "          4248,   102],\n",
      "        [  101,  4248,  3899,  4419,  4248, 14523,  2058,  2058,  3899, 13971,\n",
      "          4248,   102],\n",
      "        [  101,  2058,  2829,  3899, 14523, 13971, 13971,  2058, 14523,  2829,\n",
      "          1996,   102],\n",
      "        [  101,  3899,  1996, 14523,  4248,  3899,  1996,  1996,  3899,  4419,\n",
      "         14523,   102],\n",
      "        [  101,  2829,  1996,  2829,  2058,  2058,  2058, 13971,  1996,  4248,\n",
      "          2829,   102],\n",
      "        [  101, 14523,  4248,  2058,  4248, 13971,  4419,  1996,  1996,  2829,\n",
      "         13971,   102],\n",
      "        [  101,  4248,  1996,  4248, 13971, 14523,  2058,  4248, 13971,  2058,\n",
      "          2058,   102],\n",
      "        [  101,  1996,  4248, 13971,  2829, 14523,  2829,  4419,  1996, 14523,\n",
      "          1996,   102],\n",
      "        [  101,  2058,  2829,  3899, 13971,  2829,  4419, 13971,  4419,  2058,\n",
      "          4248,   102],\n",
      "        [  101, 14523,  2058,  2058,  1996, 13971, 13971, 13971,  2058,  4419,\n",
      "          2058,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},) and kwargs: {}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 109\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;66;03m# Run benchmarks\u001B[39;00m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRunning benchmarks...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 109\u001B[0m simple_time, dynamic_time \u001B[38;5;241m=\u001B[39m \u001B[43mbenchmark_simple_vs_dynamic\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSimple vs. Dynamic (no threads/asyncio): \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msimple_time\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms vs \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdynamic_time\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    112\u001B[0m simple_time_threaded, dynamic_time_threaded \u001B[38;5;241m=\u001B[39m benchmark_threaded()\n",
      "Cell \u001B[0;32mIn[1], line 55\u001B[0m, in \u001B[0;36mbenchmark_simple_vs_dynamic\u001B[0;34m(num_requests)\u001B[0m\n\u001B[1;32m     52\u001B[0m texts \u001B[38;5;241m=\u001B[39m [generate_random_text() \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_requests)]\n\u001B[1;32m     54\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 55\u001B[0m simple_results \u001B[38;5;241m=\u001B[39m \u001B[43msimple_batch_inference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m simple_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[1;32m     58\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "Cell \u001B[0;32mIn[1], line 40\u001B[0m, in \u001B[0;36msimple_batch_inference\u001B[0;34m(texts, batch_size)\u001B[0m\n\u001B[1;32m     38\u001B[0m     batch \u001B[38;5;241m=\u001B[39m texts[i:i\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[1;32m     39\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m tokenizer(batch, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 40\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mforward_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m     results\u001B[38;5;241m.\u001B[39mextend(outputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_hidden_state\u001B[39m\u001B[38;5;124m'\u001B[39m][:, \u001B[38;5;241m0\u001B[39m, :]\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "Cell \u001B[0;32mIn[1], line 29\u001B[0m, in \u001B[0;36mforward_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mForward called with args:\u001B[39m\u001B[38;5;124m\"\u001B[39m, args, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand kwargs:\u001B[39m\u001B[38;5;124m\"\u001B[39m, kwargs)\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 29\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/batch/batch/inference/batch_processor.py:131\u001B[0m, in \u001B[0;36mBatchProcessor.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstart()\n\u001B[1;32m    129\u001B[0m features \u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m args \u001B[38;5;28;01melse\u001B[39;00m kwargs\n\u001B[0;32m--> 131\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_schedule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/batch/batch/inference/batch_processor.py:151\u001B[0m, in \u001B[0;36mBatchProcessor._schedule\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m    146\u001B[0m new_priority_queue \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    147\u001B[0m     Item[ModelFeatures, ModelOutputs](content\u001B[38;5;241m=\u001B[39mitem, prioritized\u001B[38;5;241m=\u001B[39mprio) \u001B[38;5;28;01mfor\u001B[39;00m item, prio \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(items, prioritized)\n\u001B[1;32m    148\u001B[0m ]\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_queue\u001B[38;5;241m.\u001B[39mextend(new_priority_queue)\n\u001B[0;32m--> 151\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43mitem\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnew_priority_queue\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m stack_outputs(results)\n",
      "File \u001B[0;32m~/Documents/batch/batch/inference/batch_processor.py:151\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    146\u001B[0m new_priority_queue \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    147\u001B[0m     Item[ModelFeatures, ModelOutputs](content\u001B[38;5;241m=\u001B[39mitem, prioritized\u001B[38;5;241m=\u001B[39mprio) \u001B[38;5;28;01mfor\u001B[39;00m item, prio \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(items, prioritized)\n\u001B[1;32m    148\u001B[0m ]\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_queue\u001B[38;5;241m.\u001B[39mextend(new_priority_queue)\n\u001B[0;32m--> 151\u001B[0m results \u001B[38;5;241m=\u001B[39m [\u001B[43mitem\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m new_priority_queue]\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m stack_outputs(results)\n",
      "File \u001B[0;32m~/Documents/batch/batch/batch_generator.py:29\u001B[0m, in \u001B[0;36mItem.get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_result\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m U:\n\u001B[0;32m---> 29\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexception:\n\u001B[1;32m     31\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexception\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/threading.py:629\u001B[0m, in \u001B[0;36mEvent.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    627\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[0;32m--> 629\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.11/threading.py:327\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 327\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    328\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Benchmarking SentenceTransformers and AutoModel with and without batching\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from timeit import timeit\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import batch\n",
    "from batch import inference\n",
    "import torch\n",
    "\n",
    "# Load models\n",
    "st_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "auto_model_name = \"bert-base-uncased\"\n",
    "auto_tokenizer = AutoTokenizer.from_pretrained(auto_model_name)\n",
    "auto_model = AutoModel.from_pretrained(auto_model_name)\n",
    "\n",
    "# Helper function to generate random sentences\n",
    "def generate_random_sentences(num_sentences, words_per_sentence=10):\n",
    "    vocab = ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'lazy', 'dog']\n",
    "    return [' '.join(np.random.choice(vocab, size=words_per_sentence)) for _ in range(num_sentences)]\n",
    "\n",
    "# Benchmark functions\n",
    "def benchmark_st_no_batch(sentences):\n",
    "    return [st_model.encode(sentence) for sentence in sentences]\n",
    "\n",
    "@batch.dynamically\n",
    "def st_with_general_batch(sents: list[str]):\n",
    "    return st_model.encode(sents)\n",
    "\n",
    "@inference.dynamically\n",
    "def auto_with_inference_batch(feats):\n",
    "    with torch.no_grad():\n",
    "        outputs = auto_model(**feats)\n",
    "    return outputs.last_hidden_state\n",
    "\n",
    "\n",
    "\n",
    "def benchmark_auto_with_inference_batch(sentences):\n",
    "    inputs = auto_tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = auto_model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "# Run benchmarks\n",
    "num_sentences = 100\n",
    "sentences = generate_random_sentences(num_sentences)\n",
    "\n",
    "benchmarks = [\n",
    "    (\"SentenceTransformers (No Batch)\", lambda: benchmark_st_no_batch(sentences)),\n",
    "    (\"SentenceTransformers (General Batch)\", lambda: benchmark_st_with_general_batch(sentences)),\n",
    "    (\"AutoModel (No Batch)\", lambda: benchmark_auto_no_batch(sentences)),\n",
    "    (\"AutoModel (Inference Batch)\", lambda: benchmark_auto_with_inference_batch(sentences))\n",
    "]\n",
    "\n",
    "results = []\n",
    "for name, func in benchmarks:\n",
    "    time_taken = timeit(func, number=5) / 5  # Average over 5 runs\n",
    "    results.append((name, time_taken))\n",
    "\n",
    "# Prepare data for visualization\n",
    "df = pd.DataFrame(results, columns=['Method', 'Time (s)'])\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Method', y='Time (s)', data=df)\n",
    "plt.title('Benchmarking Results: SentenceTransformers vs AutoModel (With and Without Batching)')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display speedups\n",
    "st_speedup = df.loc[0, 'Time (s)'] / df.loc[1, 'Time (s)']\n",
    "auto_speedup = df.loc[2, 'Time (s)'] / df.loc[3, 'Time (s)']\n",
    "\n",
    "print(f\"SentenceTransformers Speedup (General Batch vs No Batch): {st_speedup:.2f}x\")\n",
    "print(f\"AutoModel Speedup (Inference Batch vs No Batch): {auto_speedup:.2f}x\")\n",
    "\n",
    "# Create speedup bar plot\n",
    "speedup_data = {\n",
    "    'Model': ['SentenceTransformers', 'AutoModel'],\n",
    "    'Speedup': [st_speedup, auto_speedup]\n",
    "}\n",
    "\n",
    "df_speedup = pd.DataFrame(speedup_data)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='Model', y='Speedup', data=df_speedup)\n",
    "plt.title('Speedup of Batched vs Non-Batched Processing')\n",
    "plt.ylabel('Speedup Factor')\n",
    "plt.show()\n",
    "\n",
    "# Restore original forward method for AutoModel\n",
    "auto_model.forward = original_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/homebrew/anaconda3/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
